{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c28dff8-7cc2-4edd-b2f3-432d89fdec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b93fda6-a007-445c-8e26-bf68c54ed584",
   "metadata": {},
   "outputs": [],
   "source": [
    "v2w_model = api.load('word2vec-google-news-300')\n",
    "sample_word2vec_embedding = v2w_model['computer'];\n",
    "\n",
    "glove_model = api.load('glove-twitter-25')\n",
    "sample_glove_embedding = glove_model['computer'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a0769a6-80f7-4a36-95ed-664a8e4fd0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding1 = v2w_model\n",
    "embedding2 = glove_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bfe15c2-9b02-45d9-a7c9-3b8feb844cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_word(line):\n",
    "    word, tag = line.split('\\t')\n",
    "    tag = tag[:-1]\n",
    "    try:\n",
    "        emb_word1 = np.append(embedding1[word], np.zeros(1))\n",
    "    except:\n",
    "        emb_word1 = np.append(np.zeros(300, dtype=\"float32\"), 100000*np.ones(1))\n",
    "    try:\n",
    "        emb_word2 = np.append(embedding2[word], np.zeros(1))\n",
    "    except:\n",
    "        emb_word2 = np.append(np.zeros(25, dtype=\"float32\"), 100000*np.ones(1))\n",
    "    emb_word = np.append(emb_word1, emb_word2)\n",
    "    tag = 1 if tag != 'O' else 0\n",
    "    return emb_word, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c390cb0-0184-4ab3-b5ce-210de43eebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        sentences = []\n",
    "        labels = []\n",
    "        curr_sen = []\n",
    "        curr_labels = []\n",
    "        for line in file.readlines():\n",
    "            if len(line.split('\\t')) > 1  and line != '\\t' and line != '\\n' and len(line.split('\\t')[-1]) > 1:\n",
    "                emb_word, tag = process_word(line)\n",
    "                curr_sen.append(emb_word)\n",
    "                curr_labels.append(tag)\n",
    "            else:\n",
    "                sentences.append(curr_sen[::])\n",
    "                labels.append(curr_labels[::])\n",
    "                curr_sen = []\n",
    "                curr_labels = []  \n",
    "        return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3dd16be-801b-4806-b2bf-5445e05a8b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, train_labels = load_data(\"data/train.tagged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27dc3354-4357-464d-a1a5-a1c16849ec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_sentences, dev_labels = load_data(\"data/dev.tagged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebf3fe26-11d2-4e38-bc22-e874963c6afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contex_embeddings(sentences):\n",
    "    contex_embs = []\n",
    "    for sent in sentences:\n",
    "        for i in range(len(sent)):\n",
    "            if i == 0:\n",
    "                if len(sent) == 1:\n",
    "                    contex_emb = np.concatenate((sent[i], sent[i], sent[i]))\n",
    "                elif len(sent) == 2:\n",
    "                    contex_emb = np.concatenate((sent[i], sent[i], sent[i+1]))\n",
    "                else:\n",
    "                    contex_emb = np.concatenate((sent[i], sent[i+1], sent[i+2]))\n",
    "            elif i == len(sent) - 1:\n",
    "                if len(sent) == 2:\n",
    "                    contex_emb = np.concatenate((sent[i], sent[i], sent[i-1]))\n",
    "                else:\n",
    "                    contex_emb = np.concatenate((sent[i], sent[i-1], sent[i-2]))\n",
    "            else:\n",
    "                contex_emb = np.concatenate((sent[i], sent[i-1], sent[i+1]))\n",
    "            contex_embs.append(contex_emb)\n",
    "    return np.array(contex_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6109fddf-ff4e-450c-80f8-4847d228be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_flat = [item for sublist in train_labels for item in sublist]\n",
    "dev_labels_flat = [item for sublist in dev_labels for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aab014e-3b04-443f-8ab4-16cdee3054fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences_flat = [item for sublist in train_sentences for item in sublist]\n",
    "dev_sentences_flat = [item for sublist in dev_sentences for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36ba204d-3b8c-4c68-910d-5904d5f77b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "KNeighborsClassifier(n_neighbors=1)",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div></div></div></div></div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier(n_neighbors=1)\n",
    "model_knn.fit(train_sentences_flat, train_labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59b89864-37e9-47ae-8e54-4371b474184e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.5831622176591376"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_dev_knn = model_knn.predict(dev_sentences_flat)\n",
    "f1_score(dev_labels_flat, predict_dev_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093e7f90-b958-40db-a889-8b788617d5da",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "697f0dab-5e87-48d0-b9af-a6c848475caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a79e2d2-88e7-4097-a3b7-2f6d8a094462",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, embeddings_flat, labels_flat):\n",
    "        self.embeddings = embeddings_flat\n",
    "        self.labels = labels_flat\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.embeddings[idx], self.labels[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "667c8a77-837c-4457-9bf2-0a3a8dff5754",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb = torch.tensor(np.array(train_sentences_flat)).float()\n",
    "dev_emb = torch.tensor(np.array(dev_sentences_flat)).float()\n",
    "train_labels = torch.tensor(np.array(train_labels_flat))\n",
    "dev_labels = torch.tensor(np.array(dev_labels_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32c7c49c-523e-460f-a704-fc772ac2c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TweetsDataset(train_emb, train_labels)\n",
    "dev_dataset = TweetsDataset(dev_emb, dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99d61611-6cec-47e5-a1a4-82fd8b36f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2eacff56-f9c0-4f63-875d-7fe1fe949b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9d758f0-82d6-4404-aa9e-c98aa6b691e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a93e2c69-9fe7-4278-9246-702521d74550",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim=327):\n",
    "        super(SentimentNN, self).__init__()\n",
    "        self.first_layer = nn.Linear(input_dim, 200)\n",
    "        self.second_layer = nn.Linear(200, 100)\n",
    "        self.third_layer = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, input_ids, labels=None):\n",
    "        x = self.first_layer(input_ids)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.second_layer(x)\n",
    "        x = nn.Tanh()(x)\n",
    "        x = self.third_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e95c711-cbd3-4de9-9f97-5324a2ff9e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(epochs, train_loader, test_loader):\n",
    "    our_net = SentimentNN()\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        our_net = our_net.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(our_net.parameters(), lr=0.001)\n",
    "    for epoch in range(epochs):\n",
    "        our_net.train()\n",
    "        for i, (sents, labels) in enumerate(train_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                sents = sents.to(device)\n",
    "                #labels = torch.cuda.LongTensor(labels)\n",
    "                labels = labels.float().to(device)\n",
    "\n",
    "            # Forward + Backward + Optimize\n",
    "            outputs = our_net(sents).view(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            if (i+1) % 300 == 0:\n",
    "                print('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' \n",
    "                       %(epoch+1, epochs, i+1,\n",
    "                         0.8 * len(train_dataset)//batch_size, loss.data))\n",
    "        our_net.eval()        \n",
    "        acc = accuracy_calc(test_loader, our_net)\n",
    "        print(acc)\n",
    "    return accuracy_calc(test_loader, our_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96bb3053-519a-4a6c-9c24-872fc3ff059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_true, y_preds):\n",
    "    return (y_true == y_preds).sum().item() / y_true.size(0)\n",
    "\n",
    "def accuracy_calc(loader, net):\n",
    "    i = sum_accuracy = 0\n",
    "    sum_loss = 0\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    # Turn off the gradients\n",
    "    with torch.no_grad():\n",
    "        # Loop through all of the validation set\n",
    "        for images, labels in loader:\n",
    "            if torch.cuda.is_available():\n",
    "                images = images.to(device)\n",
    "                #labels = torch.cuda.LongTensor(labels)\n",
    "                labels = labels.float().to(device)\n",
    "                \n",
    "            outputs = net(images).view(-1)\n",
    "            outputs[outputs > 0] = 1\n",
    "            outputs[outputs < 0] = 0\n",
    "            preds = outputs\n",
    "            sum_accuracy += get_accuracy(labels, preds)\n",
    "            sum_loss += criterion(outputs,labels)\n",
    "            i += 1\n",
    "    total_accuracy = sum_accuracy / i\n",
    "    return (total_accuracy, sum_loss / i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e100a12-c80e-4e17-80f5-c8da9b2175b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "result type Float can't be cast to the desired output type Long",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [23]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#torch.backends.cudnn.benchmark = True\u001B[39;00m\n\u001B[1;32m      2\u001B[0m num_epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m40\u001B[39m\n\u001B[0;32m----> 3\u001B[0m \u001B[43mtrain_and_test\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdev_loader\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [21]\u001B[0m, in \u001B[0;36mtrain_and_test\u001B[0;34m(epochs, train_loader, test_loader)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Forward + Backward + Optimize\u001B[39;00m\n\u001B[1;32m     17\u001B[0m outputs \u001B[38;5;241m=\u001B[39m our_net(sents)\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 18\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mcriterion\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     20\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/djangoProject3/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/djangoProject3/lib/python3.8/site-packages/torch/nn/modules/loss.py:714\u001B[0m, in \u001B[0;36mBCEWithLogitsLoss.forward\u001B[0;34m(self, input, target)\u001B[0m\n\u001B[1;32m    713\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 714\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbinary_cross_entropy_with_logits\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    715\u001B[0m \u001B[43m                                              \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    716\u001B[0m \u001B[43m                                              \u001B[49m\u001B[43mpos_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpos_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    717\u001B[0m \u001B[43m                                              \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/djangoProject3/lib/python3.8/site-packages/torch/nn/functional.py:3150\u001B[0m, in \u001B[0;36mbinary_cross_entropy_with_logits\u001B[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001B[0m\n\u001B[1;32m   3147\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (target\u001B[38;5;241m.\u001B[39msize() \u001B[38;5;241m==\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize()):\n\u001B[1;32m   3148\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTarget size (\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m) must be the same as input size (\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(target\u001B[38;5;241m.\u001B[39msize(), \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize()))\n\u001B[0;32m-> 3150\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbinary_cross_entropy_with_logits\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction_enum\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: result type Float can't be cast to the desired output type Long"
     ]
    }
   ],
   "source": [
    "#torch.backends.cudnn.benchmark = True\n",
    "num_epochs = 40\n",
    "train_and_test(num_epochs, train_loader, dev_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06d4290-cad4-4551-9dc7-9569caddfdef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142020da-e44d-4b99-b1bf-28c28d8e7881",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim=327):\n",
    "        super(SentimentNN, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, 200)\n",
    "        self.first_layer = nn.Linear(200, input_dim)\n",
    "\n",
    "    def forward(self, input_ids, labels=None):\n",
    "        x = self.lstm(input_ids)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.second_layer(x)\n",
    "        x = nn.Tanh()(x)\n",
    "        x = self.third_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf9150f-133d-45d3-bd60-b038b418ab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efdb835-d878-462e-ab99-1132aca06eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "class Model(nn.Module):\n",
    " def __init__(self, dataset):\n",
    "     super(Model, self).__init__()\n",
    "     self.lstm_size = 327\n",
    "     self.num_layers = 3\n",
    "     self.hidden_size = 100\n",
    "     self.lstm = nn.LSTM(\n",
    "     input_size=self.lstm_size,\n",
    "     hidden_size=self.hidden_size,\n",
    "     num_layers=self.num_layers,\n",
    "     dropout=0.2,\n",
    "     )\n",
    "     self.fc = nn.Linear(self.hidden_size, 1)\n",
    " def forward(self, x, prev_state):\n",
    "         output, state = self.lstm(x, prev_state)\n",
    "         logits = self.fc(output)\n",
    "         return logits, state\n",
    " def init_state(self, sequence_length):\n",
    "    return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
    "    torch.zeros(self.num_layers, sequence_length, self.lstm_size))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}